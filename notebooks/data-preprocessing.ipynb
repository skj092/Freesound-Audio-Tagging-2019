{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10700,"databundleVersionId":503808,"sourceType":"competition"}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np  # linear algebra\nimport pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport PIL\nimport pickle\nimport os\nimport argparse\nimport librosa\nimport librosa.display\nimport random\nfrom zipfile import ZipFile ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"path = Path(\"/kaggle/input/freesound-audio-tagging-2019\")\ndata_dir = Path('data')\n(data_dir/'test').mkdir(parents=True, exist_ok=True)\n(data_dir/'train_curated').mkdir(parents=True, exist_ok=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\n# loading the temp.zip and creating a zip object \nwith ZipFile(path/'test.zip', 'r') as zObject: \n    zObject.extractall(path=data_dir/'test') \nzObject.close() ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%time\n# loading the temp.zip and creating a zip object \nwith ZipFile(path/'train_curated.zip', 'r') as zObject: \n    zObject.extractall(path=data_dir/'train_curated') \nzObject.close() ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class args:\n    train_df_path = path/'train_curated.csv'\n    test_dir = data_dir/'test'\n    train_dir = data_dir/'train_curated'\n    train_output_path = data_dir/'mels_train.pkl'\n    test_output_path = data_dir/'mels_test.pkl'","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df = pd.read_csv(args.train_df_path)\ntest_fns = sorted(os.listdir(args.test_dir))\ntest_df = pd.DataFrame()\ntest_df[\"fname\"] = test_fns","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def read_audio(conf, pathname, trim_long_data):\n    y, sr = librosa.load(pathname, sr=conf.sampling_rate)\n    # trim silence\n    if 0 < len(y):  # workaround: 0 length causes error\n        y, _ = librosa.effects.trim(y)  # trim, top_db=default(60)\n    else:\n        print(f\"found zero length audio {pathname}\")\n        y = np.zeros((conf.samples,), np.float32)\n    # make it unified length to conf.samples\n    if len(y) > conf.samples:  # long enough\n        if trim_long_data:\n            y = y[0:0 + conf.samples]\n    else:  # pad blank\n        leny = len(y)\n        padding = conf.samples - len(y)  # add padding at both ends\n        offset = padding // 2\n        y = np.pad(y, (offset, conf.samples - len(y) - offset), conf.padmode)\n    return y\n\n\ndef audio_to_melspectrogram(conf, audio):\n    spectrogram = librosa.feature.melspectrogram(\n        y=audio, sr=conf.sampling_rate, n_mels=conf.n_mels, hop_length=conf.hop_length, n_fft=conf.n_fft, fmin=conf.fmin, fmax=conf.fmax)\n    spectrogram = librosa.power_to_db(spectrogram)\n    spectrogram = spectrogram.astype(np.float32)\n    return spectrogram\n\n\ndef show_melspectrogram(conf, mels, title='Log-frequency power spectrogram'):\n    librosa.display.specshow(mels, x_axis='time', y_axis='mel',\n                             sr=conf.sampling_rate, hop_length=conf.hop_length,\n                             fmin=conf.fmin, fmax=conf.fmax)\n    plt.colorbar(format='%+2.0f dB')\n    plt.title(title)\n    plt.show()\n\n\ndef read_as_melspectrogram(conf, pathname, trim_long_data):\n    x = read_audio(conf, pathname, trim_long_data)\n    mels = audio_to_melspectrogram(conf, x)\n    return mels\n\n\nclass conf:\n    sampling_rate = 16000\n    duration = 2  # sec\n    hop_length = 125 * duration  # to make time steps 128\n    fmin = 20\n    fmax = sampling_rate // 2\n    n_mels = 128\n    n_fft = n_mels * 20\n    padmode = 'constant'\n    samples = sampling_rate * duration\n\n\ndef get_default_conf():\n    return conf\n\n\ndef set_fastai_random_seed(seed=42):\n    # https://docs.fast.ai/dev/test.html#getting-reproducible-results\n    # python RNG\n    random.seed(seed)\n    # pytorch RNGs\n    import torch\n    torch.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n    # numpy RNG\n    import numpy as np\n    np.random.seed(seed)\n\n\ndef mono_to_color(X, mean=None, std=None, norm_max=None, norm_min=None, eps=1e-6):\n    # Stack X as [X,X,X]\n    X = np.stack([X, X, X], axis=-1)\n\n    # Standardize\n    mean = mean or X.mean()\n    X = X - mean\n    std = std or X.std()\n    Xstd = X / (std + eps)\n    _min, _max = Xstd.min(), Xstd.max()\n    norm_max = norm_max or _max\n    norm_min = norm_min or _min\n    if (_max - _min) > eps:\n        # Normalize to [0, 255]\n        V = Xstd\n        V[V < norm_min] = norm_min\n        V[V > norm_max] = norm_max\n        V = 255 * (V - norm_min) / (norm_max - norm_min)\n        V = V.astype(np.uint8)\n    else:\n        # Just zero\n        V = np.zeros_like(Xstd, dtype=np.uint8)\n    return V\n\n\ndef convert_wav_to_image(df, source):\n    X = []\n    for i, row in tqdm(df.iterrows(), total=len(df)):\n        x = read_as_melspectrogram(\n            conf, source / str(row.fname), trim_long_data=False)\n        x_color = mono_to_color(x)\n        X.append(x_color)\n    return X\n\n\ndef save_as_pkl_binary(obj, filename):\n    \"\"\"Save object as pickle binary file.\n    Thanks to https://stackoverflow.com/questions/19201290/how-to-save-a-dictionary-to-a-file/32216025\n    \"\"\"\n    with open(filename, 'wb') as f:\n        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n\n\ndef load_pkl(filename):\n    \"\"\"Load pickle object from file.\"\"\"\n    with open(filename, 'rb') as f:\n        return pickle.load(f)\n\n\nconf = get_default_conf()\n\n\ndef convert_dataset(df, source_folder, filename):\n    X = convert_wav_to_image(df, source=source_folder)\n    save_as_pkl_binary(X, filename)\n    print(f'Created {filename}')\n    return X","metadata":{"_uuid":"cc10923e-1d4a-457e-a576-4568e40ab7c7","_cell_guid":"135f4bea-2c99-4505-94b0-83b0266d5567","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"convert_dataset(train_df, Path(args.train_dir), args.train_output_path)\nconvert_dataset(test_df, Path(args.test_dir), args.test_output_path)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!rm -rf \"data/train_curated\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T06:21:12.484075Z","iopub.execute_input":"2025-01-09T06:21:12.484475Z","iopub.status.idle":"2025-01-09T06:21:12.607177Z","shell.execute_reply.started":"2025-01-09T06:21:12.484441Z","shell.execute_reply":"2025-01-09T06:21:12.605794Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!rm -rf \"data/test\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T06:21:13.545027Z","iopub.execute_input":"2025-01-09T06:21:13.545426Z","iopub.status.idle":"2025-01-09T06:21:13.668102Z","shell.execute_reply.started":"2025-01-09T06:21:13.545394Z","shell.execute_reply":"2025-01-09T06:21:13.666254Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}